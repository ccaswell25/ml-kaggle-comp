# Overview:

The final lab for our Machine Learning course will be to train models to predict dissolved inorganic carbon in water samples collected by the California Cooperative Oceanic Fisheries Investigations program (CalCOFI). This is a part of a class-wide Kaggle competition, completed on March 23rd.

This data will be used to train a model that will predict dissolved inorganic carbon (DIC) content in water samples from CalCOFI.

Details on the database are located here: <https://calcofi.org/data/oceanographic-data/bottle-database/>

## Load Libraries:

```{r warning = FALSE, message = FALSE}
library(tidymodels)
library(dplyr)
library(here)
library(tidyverse)
library(kernlab)
```

## Read in the Data:

```{r warning = FALSE, message = FALSE}
dic_train <- read_csv(here("train.csv"))
dic_test <- read_csv(here("test.csv"))
```

## Explore the Data:

```{r warning = FALSE, message = FALSE}
# Data Exploration ---
head(dic_train)

glimpse(dic_train)
```

## Choose Model Algorithm:

We chose...... because ......
```{r warning = FALSE, message = FALSE}
#Options: KNN, RF, Decision Tree, Clustering, Bagged Tree, Boosted Tree, SVM, Neural Net
```

## Pre-Processing:

```{r warning = FALSE, message = FALSE}
# Create the recipe ---
dic_rec <- recipe(DIC ~ ., data = dic_train) %>% 
  step_zv(all_predictors()) %>% #is this needed?
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors())
  
# Preprocessing ---
dic_model <- rand_forest(mtry = tune(), trees = tune()) %>% #this will change depending on what model we choose
  set_engine("randomForest") %>% #this will change depending on what model we choose
  set_mode("regression")

# Specifying Workflow ---
dic_workflow = workflow() %>% 
  add_model(dic_model) %>% 
  add_recipe(dic_rec)
```


## Tune Relevant Parameters (Cross validation):

```{r warning = FALSE, message = FALSE}
#Creating folds for cross validation ---
set.seed(1234)
folds <-vfold_cv(dic_train, strata = DIC)

#Set up Grid ---
#which one to use will depend on our model....?
grid <- grid_regular(cost(), levels = 10)
grid <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))
grid <- grid_latin_hypercube(trees(),
                                  tree_depth(),
                                  loss_reduction(),
                                  min_n(),
                                  size = 10)

#Tune the Model ---
fit_dic <- dic_workflow %>% 
tune_grid(
  resamples = folds,
 grid = grid) 
```

## Final Predictions:

```{r warning = FALSE, message = FALSE}
# Final Predictions ---
# Finalizing workflow with best metrics ---
best_model_params = dic_workflow %>% 
  finalize_workflow(select_best(fit_dic, metric = "accuracy"))

# Fit the model to the training set ---
 fit_model = fit(best_model_params, dic_train)

# Test predictions on model ---
predict_model = predict(fit_model, dic_test) %>% 
  bind_cols(dic_test)

# Store accuracy of testing prediction ---
accuracy <- accuracy(predict_model, truth = DIC, estimate = .pred_class)

print(paste0("I get an accuracy measure of ", round(accuracy[,3], 2), " with this model."))

```
